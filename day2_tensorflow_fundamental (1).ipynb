{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HfzgXXiSGlG",
        "outputId": "1e96abdf-1f2d-458e-f938-f1a6d4cea315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "scalar = tf.constant(7)\n",
        "vector = tf.constant([2,3])\n",
        "matrix = tf.constant([[1,2,3], [4,5,6,]])\n",
        "array_3d = tf.constant([[[1,2,3],[4,5,6]]\n",
        "                       ,[[2,3,4,],[5,6,7]]])\n",
        "\n",
        "#printing the shape of scaler will result in ()\n",
        "print(scalar.shape)\n",
        "# #printing the shape of matrix\n",
        "print(matrix.shape)\n",
        "# #printing the shape of 3d array\n",
        "print(array_3d.shape)\n",
        "\n",
        "#now we are going to print the type of tensors\n",
        "print(scalar.dtype)\n",
        "print(vector.dtype)\n",
        "print(matrix.dtype)\n",
        "print(array_3d.dtype)\n",
        "#the answer would be \"int32\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydwI1wW8Yjux",
        "outputId": "d00733e0-f94a-4e29-d8d1-fe3d39ae5a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'int32'>\n",
            "<dtype: 'int32'>\n",
            "<dtype: 'int32'>\n",
            "<dtype: 'int32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we are going to print the dimensions of each exampple we have taken of tensors\n",
        "#we can use the arrays/tensors made in the previos cell\n",
        "#also we dont have to import tensorflow and numpy again\n",
        "\n",
        "print(scalar.ndim)\n",
        "print(vector.ndim)\n",
        "print(matrix.ndim)\n",
        "print(array_3d.ndim)\n",
        "#we have made the tensors of 3 dimensions yet , in the next cell we are going\n",
        "#make tensors of 4 dimensions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKZz7RkzauSD",
        "outputId": "8682f8d3-cc93-4bd6-c2b7-f84cb65da009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we are going to make 4 dimensions tensors now\n",
        "element = np.random.rand(32,224,224,3)\n",
        "print(element.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiq9Lh_tbpL4",
        "outputId": "95fa4d76-2f85-4c22-ff18-dca34aa0ef0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty 4D tensor\n",
        "tensor_4d = np.zeros((5, 128, 128, 1))\n",
        "print(f\"Shape: {tensor_4d.shape}\")\n",
        "# Output: Shape: (5, 128, 128, 1)\n",
        "#         5 grayscale images, 128x128 pixels"
      ],
      "metadata": {
        "id": "Nzokm6RjfHoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have 3 images (example)\n",
        "image1 = np.random.rand(100, 100, 3)  # Single image\n",
        "image2 = np.random.rand(100, 100, 3)\n",
        "image3 = np.random.rand(100, 100, 3)\n",
        "\n",
        "# Stack them into 4D tensor\n",
        "batch = np.stack([image1,image2,image3])\n",
        "print(f\"shape: {batch.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpUhMWgOfLWa",
        "outputId": "d2d51dc0-0bb5-4268-b76b-c8dc076c19c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (3, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Accessing Elements in 4D Tensor\n"
      ],
      "metadata": {
        "id": "B21rc5MUio-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making a 4D tensor\n",
        "tensor = np.random.rand(2,3,3,2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#accesing first image only\n",
        "print(tensor[0]) # because we only need the first image\n",
        "\n",
        "#accessing the first pixel\n",
        "print(tensor[0,0,0]) #first pixel of first image\n",
        "\n",
        "#accesing only red channel\n",
        "print(tensor[0,:, :, 0])\n",
        "\n",
        "#accessing the second image's blue channel\n",
        "print(tensor[1,:,:,1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MEb21qTmiw4y",
        "outputId": "8bd4a190-bdad-4603-e414-d11df783d317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.78658906 0.55140162]\n",
            "  [0.37921171 0.69994081]\n",
            "  [0.75106006 0.59646659]]\n",
            "\n",
            " [[0.18403388 0.2793714 ]\n",
            "  [0.17410989 0.88808489]\n",
            "  [0.56668178 0.23184078]]\n",
            "\n",
            " [[0.7127089  0.252723  ]\n",
            "  [0.91509975 0.70640474]\n",
            "  [0.53768807 0.35951753]]]\n",
            "[0.78658906 0.55140162]\n",
            "[[0.78658906 0.37921171 0.75106006]\n",
            " [0.18403388 0.17410989 0.56668178]\n",
            " [0.7127089  0.91509975 0.53768807]]\n",
            "[[0.76273982 0.42008261 0.53919433]\n",
            " [0.6183086  0.65492895 0.79181122]\n",
            " [0.22532249 0.03492538 0.93105858]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common 4D Tensor Formats"
      ],
      "metadata": {
        "id": "gjHdy1WMmlHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #most common imagess\n",
        "\n",
        "#   (batch_size, height, width, channels)\n",
        "# Example: (32, 224, 224, 3)\n",
        "# - 32 images\n",
        "# - 224x224 pixels each\n",
        "# - RGB (3 channels)\n",
        "\n",
        "\n",
        "# #videoss formatt\n",
        "# (batch_size, frames, height, width)\n",
        "# Example: (8, 30, 64, 64)\n",
        "# - 8 videos\n",
        "# - 30 frames per video\n",
        "# - 64x64 pixels per frame\n",
        "\n",
        "\n",
        "\n",
        "# #time seriesss format\n",
        "# (batch_size, time_steps, features, channels)\n",
        "# Example: (16, 100, 10, 1)\n",
        "# # - 16 sequences\n",
        "# # - 100 time steps\n",
        "# # - 10 features\n",
        "# - 1 channel"
      ],
      "metadata": {
        "id": "NY_JCMTTmnEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "np_array = np.array([[1,2],[3,4]])\n",
        "\n",
        "tensor_flow = tf.constant([[1,2],[4,5]])\n",
        "\n",
        "print(type(np_array))\n",
        "print(type(tensor_flow))\n",
        "\n",
        "\n",
        "#we do the conversion here fron tensor to numpy an dnumpy to tensor\n",
        "tensor_from_numpy = tf.constant(np_array)\n",
        "numpy_from_tensor = tensor_flow.numpy()\n",
        "print(type(tensor_from_numpy))\n",
        "print(type(numpy_from_tensor))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#now we are going to do the excercise\n",
        "#aatep one to make a numpyarray\n",
        "array = np.array([[1,2],[3,4]])\n",
        "numpy_to_tensor = tf.constant(array)\n",
        "array_2 = np.array([array ** 5])\n",
        "\n",
        "#convert back into tensor flow\n",
        "tensor_to_numpy = numpy_to_tensor.numpy()\n",
        "\n",
        "print(f\"the original array is: {array}\")\n",
        "print(f\"the Converted array is: {numpy_to_tensor}\")\n",
        "print(f\"the Multiplication with 5 results in : {array_2}\")\n",
        "print(f\"again converted to tensor is: {tensor_to_numpy}\")\n",
        "#one mistake i made here is that i used the .numpy() method with array_2\n",
        "#array_2 is a numpy array and it does not have a .numpy method\n",
        "#we make the numpy_to_tensor is a tensor , conveted by .numpy()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e1pm3js0zfaX",
        "outputId": "2956a2f8-3829-488d-f21d-aa4537d8cbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "the original array is: [[1 2]\n",
            " [3 4]]\n",
            "the Converted array is: [[1 2]\n",
            " [3 4]]\n",
            "the Multiplication with 5 results in : [[[   1   32]\n",
            "  [ 243 1024]]]\n",
            "again converted to tensor is: [[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise operations\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "b = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "print(\"Addition:\", tf.add(a, b))  # or just a + b\n",
        "print(\"Multiplication:\", tf.multiply(a, b))  # element-wise\n",
        "print(\"Matrix multiplication:\", tf.matmul(a, b))  # THIS IS DIFFERENT!\n",
        "\n",
        "\n",
        "# YOUR TASK:\n",
        "# 1. What's the difference between tf.multiply and tf.matmul?\n",
        "# 2. Try both and compare outputs\n",
        "# 3. When would you use each one in neural networks?\n",
        "\n",
        "# Hint: Neural networks use matrix multiplication constantly!"
      ],
      "metadata": {
        "id": "_NZcXT485iey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#example for tf.multiply\n",
        "     [[1, 2],      [[5, 6],      [[1√ó5, 2√ó6],      [[5, 12],\n",
        "     [3, 4]]   √ó   [7, 8]]   =   [3√ó7, 4√ó8]]   =   [21, 32]]\n",
        "     \n",
        "Same position elements multiply together!\n",
        "Position (0,0): 1 √ó 5 = 5\n",
        "Position (0,1): 2 √ó 6 = 12\n",
        "Position (1,0): 3 √ó 7 = 21\n",
        "Position (1,1): 4 √ó 8 = 32\n",
        "\n",
        "\n",
        "\n",
        "#example for tf.matmultiply\n",
        "[[1, 2],      [[5, 6],      \n",
        "     [3, 4]]   @   [7, 8]]   \n",
        "     \n",
        "Row √ó Column operations:\n",
        "(0,0): 1√ó5 + 2√ó7 = 19\n",
        "(0,1): 1√ó6 + 2√ó8 = 22\n",
        "(1,0): 3√ó5 + 4√ó7 = 43\n",
        "(1,1): 3√ó6 + 4√ó8 = 50\n",
        "\n",
        "Result: [[19, 22],\n",
        "         [43, 50]]"
      ],
      "metadata": {
        "id": "3vlXUZdXzbTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create two matrices\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "b = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "element_wise = tf.multiply(a, b)\n",
        "print(element_wise.numpy())\n",
        "\n",
        "matrix_mult = tf.matmul(a, b)\n",
        "print(matrix_mult.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFzFjvMwzOcf",
        "outputId": "fa4c2b92-c5fb-41af-e2f9-b29767f9a0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 12]\n",
            " [21 32]]\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tf.multiply (Element-wise) - Use for:\n",
        "\n",
        "Attention Mechanisms\n",
        "\n",
        "Dropout / Masking\n",
        "\n",
        "Gating Mechanisms (LSTM, GRU)\n"
      ],
      "metadata": {
        "id": "9IGBmn3x0yiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########ATTENTION MECHANISM#######\n",
        "\n",
        "# Scale certain features\n",
        "attention_weights = tf.constant([[0.8, 0.2], [0.3, 0.7]])\n",
        "features = tf.constant([[10, 20], [30, 40]])\n",
        "weighted_features = tf.multiply(attention_weights, features)\n",
        "# Result: [[8, 4], [9, 28]] - scaled by attention\n",
        "\n",
        "\n",
        "#######DROPOUT/MASKINGG########\n",
        "# Randomly drop neurons\n",
        "dropout_mask = tf.constant([[1, 0], [1, 1]], dtype=tf.float32)\n",
        "activations = tf.constant([[5.0, 3.0], [2.0, 4.0]])\n",
        "dropped = tf.multiply(activations, dropout_mask)\n",
        "# Result: [[5, 0], [2, 4]] - some neurons zeroed out"
      ],
      "metadata": {
        "id": "-fbD-vLd1PQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM and GRU = Neural networks with MEMORY\n",
        "They can remember things from the past while learning new things!\n",
        "\n",
        "üìñ Why Do We Need Memory?\n",
        "Problem with Regular Neural Networks:\n",
        "Imagine reading a sentence word by word:\n",
        "\"The cat sat on the ___\"\n",
        "To fill in the blank, you need to REMEMBER:\n",
        "\n",
        "‚úÖ There's a \"cat\" (from earlier)\n",
        "‚úÖ The word \"on\" suggests a place\n",
        "\n",
        "Regular neural networks FORGET earlier words!\n",
        "\n",
        "üí° Real Life Example:\n",
        "You (Human with Memory):\n",
        "Word 1: \"The\"     ‚Üí Remember: article\n",
        "Word 2: \"cat\"     ‚Üí Remember: animal, subject\n",
        "Word 3: \"sat\"     ‚Üí Remember: past action\n",
        "Word 4: \"on\"      ‚Üí Remember: preposition\n",
        "Word 5: \"the\"     ‚Üí Remember: another article\n",
        "Word 6: ???       ‚Üí You know: \"mat\" or \"floor\" (because you remember CAT + SAT + ON)\n",
        "Regular Neural Network (No Memory):\n",
        "Word 1: \"The\"     ‚Üí Process... forget\n",
        "Word 2: \"cat\"     ‚Üí Process... forget\n",
        "Word 3: \"sat\"     ‚Üí Process... forget\n",
        "Word 4: \"on\"      ‚Üí Process... forget\n",
        "Word 5: \"the\"     ‚Üí Process... forget\n",
        "Word 6: ???       ‚Üí \"Uh... I forgot what we were talking about\"\n",
        "LSTM/GRU = Networks that REMEMBER!\n",
        "\n",
        "üîÑ What Are They Used For?\n",
        "1. Language (Text)\n",
        "\n",
        "Translation: \"Hello\" ‚Üí \"Hola\"\n",
        "Chatbots: Remember conversation\n",
        "Text generation: Write stories\n",
        "\n",
        "2. Time Series\n",
        "\n",
        "Stock prices: Remember trends\n",
        "Weather prediction: Remember patterns\n",
        "Sales forecasting\n",
        "\n",
        "3. Speech & Audio\n",
        "\n",
        "Speech recognition: \"Hey Siri\"\n",
        "Music generation\n",
        "\n",
        "4. Video\n",
        "\n",
        "Action recognition: What's happening?\n",
        "Video captioning\n",
        "\n",
        "Basically: ANYTHING that happens over TIME!"
      ],
      "metadata": {
        "id": "bAiJx5vMtbpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM (Long Short-Term Memory)\n",
        "Think of LSTM as a SMART NOTEBOOK with 3 DECISIONS:\n",
        "\n",
        "‚îÇ      üìì LSTM Memory Cell            \n",
        "‚îÇ                                   \n",
        "‚îÇ  üö™ Gate 1: FORGET GATE           \n",
        "‚îÇ     \"Should I erase old notes?\"     \n",
        "‚îÇ                                    \n",
        "‚îÇ  üö™ Gate 2: INPUT GATE             \n",
        "‚îÇ     \"Should I write new notes?\"     \n",
        "‚îÇ                                     \n",
        "‚îÇ  üö™ Gate 3: OUTPUT GATE            \n",
        "‚îÇ     \"Should I share my notes?\"      \n",
        "\n",
        "Example: Reading a Story\n",
        "Sentence: \"John went to Paris. He loved the city.\"\n",
        "\n",
        "Processing \"John\":\n",
        " Forget Gate: \"Don't forget anything yet\" (keep = 1.0)\n",
        "Input Gate:  \"Remember: main character is John\" (write = 0.9)Output Gate: \"Yes, output this info\" (show = 0.8)\n",
        "\n",
        "Processing \"Paris\":\n",
        " Forget Gate: \"Keep John in memory\" (keep = 0.9)\n",
        " Input Gate:  \"Remember: location is Paris\" (write = 0.9)\n",
        " Output Gate: \"Output location info\" (show = 0.7)\n",
        "\n",
        "Processing \"He\":\n",
        " Forget Gate: \"Keep John (main character)\" (keep = 1.0)\n",
        " Input Gate:  \"He = John (already know)\" (write = 0.1)\n",
        " Output Gate: \"Connect 'He' to 'John'\" (show = 0.9)\n",
        "       ‚Üë\n",
        "    Remembers \"John\" from earlier!\n",
        "\n",
        "üéØ LSTM Structure (Simple View)\n",
        "python# Imagine each gate as a percentage (0-1)\n",
        "\n",
        "# === STEP 1: FORGET GATE ===\n",
        "\"What should I forget from memory?\"\n",
        "forget_gate = 0.8  # Keep 80%, forget 20%\n",
        "old_memory = old_memory √ó 0.8\n",
        "\n",
        "# === STEP 2: INPUT GATE ===\n",
        "\"What new information should I remember?\"\n",
        "input_gate = 0.6   # Remember 60% of new info\n",
        "new_info = current_input √ó 0.6\n",
        "memory = old_memory + new_info\n",
        "\n",
        "# === STEP 3: OUTPUT GATE ===\n",
        "\"What should I output?\"\n",
        "output_gate = 0.9  # Show 90% of memory\n",
        "output = memory √ó 0.9"
      ],
      "metadata": {
        "id": "sE1zGss4tv5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU (Gated Recurrent Unit)\n",
        "Think of GRU as a SIMPLER LSTM:\n",
        "\n",
        "‚îÇ      üìù GRU Memory Cell             \n",
        "‚îÇ                                     \n",
        "‚îÇ  üö™ Gate 1: UPDATE GATE            \n",
        "‚îÇ     \"How much should I update?\"    \n",
        "‚îÇ                                    \n",
        "‚îÇ  üö™ Gate 2: RESET GATE             \n",
        "‚îÇ     \"Should I forget the past?\"     \n",
        "‚îÇ                                     \n",
        "‚îÇ  (Simpler = Faster = Popular!)      \n",
        "\n",
        "GRU = LSTM with fewer gates (2 instead of 3)"
      ],
      "metadata": {
        "id": "o9IKcLe-xE_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################LSTM###############\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create LSTM layer\n",
        "model = tf.keras.Sequential([\n",
        "    # Input: sequences of 100 time steps, each with 10 features\n",
        "    tf.keras.layers.LSTM(64, input_shape=(100, 10)),\n",
        "    #                    ‚Üë\n",
        "    #              64 memory cells\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Example: Predict next word\n",
        "# Input: \"The cat sat on\"\n",
        "# LSTM remembers: cat, sat, on\n",
        "# Output: \"the\" (mat/floor likely next)\n",
        "\n",
        "\n",
        "##################GRU#################\n",
        "# Same thing, but with GRU\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(64, input_shape=(100, 10)),\n",
        "    #                   ‚Üë\n",
        "    #           Simpler, faster than LSTM\n",
        "\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zp2L7vx7xeB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** ##matmul (Matrix Multiplication) - Use for**\n",
        "\n",
        " Dense/Fully Connected Layers\n",
        "\n",
        " Batch Processing\n",
        "\n",
        " Convolutional Layers (Behind the scenes)"
      ],
      "metadata": {
        "id": "r6auriDm1k9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###DENSE OR FULLY CONNECTED LAYERSS#######\n",
        "\n",
        "# This is THE CORE of neural networks!\n",
        "inputs = tf.constant([[1.0, 2.0, 3.0]])  # Input features (1, 3)\n",
        "weights = tf.constant([\n",
        "    [0.1, 0.2],  # Weight for neuron 1\n",
        "    [0.3, 0.4],  # Weight for neuron 2\n",
        "    [0.5, 0.6]   # Weight for neuron 3\n",
        "])  # Shape: (3, 2) - transforms 3 features to 2 neurons\n",
        "\n",
        "output = tf.matmul(inputs, weights)  # (1, 3) @ (3, 2) = (1, 2)\n",
        "# Result: [[2.2, 2.8]] - activations of 2 neurons\n",
        "\n",
        "\n",
        "\n",
        "####BATCH PROCESSING####\n",
        "\n",
        "# Process multiple samples at once\n",
        "batch_inputs = tf.constant([\n",
        "    [1.0, 2.0],  # Sample 1\n",
        "    [3.0, 4.0],  # Sample 2\n",
        "    [5.0, 6.0]   # Sample 3\n",
        "])  # Shape: (3, 2) - 3 samples, 2 features\n",
        "\n",
        "weights = tf.constant([\n",
        "    [0.5, 0.3, 0.2],  # 3 neurons\n",
        "    [0.1, 0.4, 0.7]\n",
        "])  # Shape: (2, 3)\n",
        "\n",
        "outputs = tf.matmul(batch_inputs, weights)  # (3, 2) @ (2, 3) = (3, 3)\n",
        "# Each of 3 samples gets transformed to 3 neuron outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# CNNs use matrix multiplication for efficient convolution\n",
        "# Flattened patches √ó filters = feature maps"
      ],
      "metadata": {
        "id": "wuH1BLVK2TOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have 3 numbers: [1.0, 2.0, 3.0]\n",
        "You want to get 2 neurons (neuron 1 and neuron 2)\n",
        "\n",
        "NEURON 1 (first column of weights):\n",
        "= 1.0√ó0.1 + 2.0√ó0.3 + 3.0√ó0.5\n",
        "= 0.1 + 0.6 + 1.5\n",
        "= 2.2 ‚úÖ\n",
        "\n",
        "NEURON 2 (second column of weights):\n",
        "= 1.0√ó0.2 + 2.0√ó0.4 + 3.0√ó0.6\n",
        "= 0.2 + 0.8 + 1.8\n",
        "= 2.8 ‚úÖ\n",
        "\n",
        "Output: [2.2, 2.8]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####BATCH PROCESSING\n",
        "\n",
        "batch_inputs = [[1.0, 2.0],  # Person 1\n",
        "                [3.0, 4.0],  # Person 2\n",
        "                [5.0, 6.0]]  # Person 3\n",
        "\n",
        "weights = [[0.5, 0.3, 0.2],  # Transform into 3 neurons\n",
        "           [0.1, 0.4, 0.7]]\n",
        "\n",
        "outputs = batch_inputs @ weights\n",
        "\n",
        "\n",
        "\n",
        "PERSON 1: [1.0, 2.0 Neuron 2: 1.0√ó0.3 + 2.0√ó0.4] = 0.3 + 0.8 = 1.1\n",
        "\n",
        " Neuron 1: 1.0√ó0.5 + 2.0√ó0.1 = 0.5 + 0.2 = 0.7\n",
        "\n",
        "Neuron 3: 1.0√ó0.2 + 2.0√ó0.7 = 0.2 + 1.4 = 1.6\n",
        "\n",
        "\n",
        "PERSON 2: [3.0, 4.0]\n",
        "\n",
        "Neuron 1: 3.0√ó0.5 + 4.0√ó0.1 = 1.5 + 0.4 = 1.9\n",
        "\n",
        " Neuron 2: 3.0√ó0.3 + 4.0√ó0.4 = 0.9 + 1.6 = 2.5\n",
        "\n",
        " Neuron 3: 3.0√ó0.2 + 4.0√ó0.7 = 0.6 + 2.8 = 3.4\n",
        "\n",
        "\n",
        "PERSON 3: [5.0, 6.0]\n",
        "\n",
        "Neuron 1: 5.0√ó0.5 + 6.0√ó0.1 = 2.5 + 0.6 = 3.1\n",
        "\n",
        " Neuron 2: 5.0√ó0.3 + 6.0√ó0.4 = 1.5 + 2.4 = 3.9\n",
        "\n",
        " Neuron 3: 5.0√ó0.2 + 6.0√ó0.7 = 1.0 + 4.2 = 5.2\n",
        "\n",
        "\n",
        "Output:\n",
        "\n",
        "[[0.7, 1.1, 1.6],   ‚Üê Person 1's results\n",
        "\n",
        " [1.9, 2.5, 3.4],   ‚Üê Person 2's results\n",
        "\n",
        " [3.1, 3.9, 5.2]]   ‚Üê Person 3's results"
      ],
      "metadata": {
        "id": "L4OXG9TE4VVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is CRUCIAL for neural networks\n",
        "tensor = tf.constant([[1, 2, 3, 4, 5, 6]])\n",
        "print(\"Original shape:\", tensor.shape)  # (1, 6)\n",
        "\n",
        "# Reshape to different dimensions\n",
        "reshaped_2x3 = tf.reshape(tensor, (2, 3))\n",
        "reshaped_3x2 = tf.reshape(tensor, (3, 2))\n",
        "reshaped_6x1 = tf.reshape(tensor, (6, 1))\n",
        "\n",
        "print(\"2x3:\", reshaped_2x3)\n",
        "print(\"3x2:\", reshaped_3x2)\n",
        "print(\"6x1:\", reshaped_6x1)\n",
        "\n",
        "# YOUR TASKS:\n",
        "# 1. Create a tensor of shape (4, 4) with values 1-16\n",
        "# 2. Reshape it to (2, 8)\n",
        "# 3. Reshape it to (8, 2)\n",
        "# 4. Try to reshape to (3, 5) - what happens? Why?\n",
        "# 5. Use tf.reshape with -1: tf.reshape(tensor, (2, -1))\n",
        "#    What does -1 do? (This is a powerful trick!)"
      ],
      "metadata": {
        "id": "KGAsdSje5lWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create 16 numbers arranged in 4√ó4\n",
        "tensor = tf.constant([\n",
        "    [1,  2,  3,  4],\n",
        "    [5,  6,  7,  8],\n",
        "    [9,  10, 11, 12],\n",
        "    [13, 14, 15, 16]\n",
        "])\n",
        "print(\"Original (4√ó4):\")\n",
        "print(tensor.numpy()) #converting into a numpy array by using .numpy( method)\n",
        "print(\"Shape:\", tensor.shape)  # (4, 4)\n",
        "\n",
        "\n",
        "\n",
        "#####reshaping into 2x8  ####\n",
        "reshaped_2x8 = tf.reshape(tensor, (2, 8))\n",
        "print(\"Reshaped to 2√ó8:\")\n",
        "print(reshaped_2x8.numpy())\n",
        "\n",
        "#reshaped to 8x2 ######\n",
        "reshaped_8x2 = tf.reshape(tensor, (8, 2))\n",
        "print(\"Reshaped to 8√ó2:\")\n",
        "print(reshaped_8x2.numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###reshaping in 3x5 ########\n",
        "try:\n",
        "    reshaped_3x5 = tf.reshape(tensor, (3, 5))\n",
        "except Exception as e:\n",
        "    print(\"\\n‚ùå ERROR!\")\n",
        "    print(\"Why? 3√ó5 = 15, but we have 16 elements!\")\n",
        "    print(\"Can't fit 16 numbers into 15 spaces!\")\n",
        "\n",
        "\n",
        "# Let TensorFlow calculate one dimension automatically!\n",
        "reshaped_auto = tf.reshape(tensor, (2, -1))\n",
        "#                                   \"You figure this out!\"\n",
        "\n",
        "print(\"\\nUsing -1 (auto-calculate):\")\n",
        "print(\"Shape:\", reshaped_auto.shape)  # (2, 8)\n",
        "print(reshaped_auto.numpy())\n",
        "\n",
        "\n",
        "                           # You say: \"I want ? rows, 2 columns\"\n",
        "result = tf.reshape(tensor, (-1, 2))\n",
        "# TensorFlow: \"6 √∑ 2 = 3 rows\"\n",
        "# Result: (3, 2)\n",
        "\n",
        "print(result.numpy())\n",
        "# [[1, 2],\n",
        "#  [3, 4],\n",
        "#  [5, 6]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZCqUYE9k0H2j",
        "outputId": "128740c1-d365-4032-b193-de3f842608bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original (4√ó4):\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15 16]]\n",
            "Shape: (4, 4)\n",
            "Reshaped to 2√ó8:\n",
            "[[ 1  2  3  4  5  6  7  8]\n",
            " [ 9 10 11 12 13 14 15 16]]\n",
            "Reshaped to 8√ó2:\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]\n",
            " [13 14]\n",
            " [15 16]]\n",
            "\n",
            "‚ùå ERROR!\n",
            "Why? 3√ó5 = 15, but we have 16 elements!\n",
            "Can't fit 16 numbers into 15 spaces!\n",
            "\n",
            "Using -1 (auto-calculate):\n",
            "Shape: (2, 8)\n",
            "[[ 1  2  3  4  5  6  7  8]\n",
            " [ 9 10 11 12 13 14 15 16]]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]\n",
            " [13 14]\n",
            " [15 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##the uses of Reshaping in tensor flow\n",
        "#####image processing#######\n",
        "\n",
        "# Image comes in: (height, width, channels)\n",
        "image = tf.random.normal((28, 28, 1))  # 28√ó28 grayscale image\n",
        "\n",
        "# Flatten for Dense layer\n",
        "flattened = tf.reshape(image, (1, -1))  # (1, 784)\n",
        "# Now it's: 1 sample with 784 features!\n",
        "\n",
        "# Can feed to neural network\n",
        "# Dense layer expects: (batch_size, features)\n",
        "\n",
        "\n",
        "#####Batch processing#######\n",
        "# Have 100 images\n",
        "images = tf.random.normal((100, 28, 28, 1))\n",
        "\n",
        "# Reshape each image to 784 features\n",
        "reshaped = tf.reshape(images, (100, -1))  # (100, 784)\n",
        "# Now: 100 samples, each with 784 features"
      ],
      "metadata": {
        "id": "q0s7riXI5U_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNDERSTANDING COMPUTATIONAL GRAPHS_______________________\n",
        "\n",
        "# TensorFlow builds a graph of operations\n",
        "x = tf.constant(3.0)\n",
        "y = tf.constant(4.0)\n",
        "z = x + y\n",
        "\n",
        "print(\"Result:\", z)\n",
        "\n",
        "# The graph: x --> [+] <-- y --> z\n",
        "# This allows TensorFlow to:\n",
        "# 1. Optimize the computation\n",
        "# 2. Calculate gradients automatically (for backpropagation)\n",
        "# 3. Run on GPUs efficiently\n",
        "\n",
        "# YOUR TASK:\n",
        "# Build a computational graph for this equation:\n",
        "# result = (a * b) + (c / d) - e\n",
        "# Where a=2, b=3, c=10, d=2, e=1\n",
        "# Print the result\n",
        "# Think: What operations are happening in what order?"
      ],
      "metadata": {
        "id": "eT1-xJ7f5oRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3651ba9b-6900-4fad-f1ff-7ddf153a966f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: tf.Tensor(7.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A computational graph = A recipe showing step-by-step calculations\n",
        "#Think of it like a flowchart for math\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Create inputs\n",
        "x = tf.constant(3.0)\n",
        "y = tf.constant(4.0)\n",
        "\n",
        "# Step 2: Build the graph (define operations)\n",
        "z = x + y\n",
        "\n",
        "# Step 3: Result\n",
        "print(\"Result:\", z.numpy())  # 7.0\n",
        "\n",
        "\n",
        "\n",
        "#####task1\n",
        "# Step 1: Define all inputs\n",
        "a = tf.constant(2.0)\n",
        "b = tf.constant(3.0)\n",
        "c = tf.constant(10.0)\n",
        "d = tf.constant(2.0)\n",
        "e = tf.constant(1.0)\n",
        "\n",
        "# Step 2: Build the graph (break down the equation)\n",
        "multiply = a * b      # 2 * 3 = 6\n",
        "divide = c / d        # 10 / 2 = 5\n",
        "add = multiply + divide   # 6 + 5 = 11\n",
        "result = add - e      # 11 - 1 = 10\n",
        "\n",
        "# Step 3: Print result\n",
        "print(\"Result:\", result.numpy())  # 10.0\n",
        "\n",
        "# Alternative: Do it in one line (same graph!)\n",
        "result_oneline = (a * b) + (c / d) - e\n",
        "print(\"One-line result:\", result_oneline.numpy())  # 10.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# a (2) ‚îÄ‚îÄ‚îê\n",
        "#             ‚îú‚îÄ‚îÄ‚Üí [√ó] ‚îÄ‚îÄ‚Üí multiply (6) ‚îÄ‚îÄ‚îê\n",
        "#     b (3) ‚îÄ‚îÄ‚îò                           ‚îÇ\n",
        "#                                         ‚îú‚îÄ‚îÄ‚Üí [+] ‚îÄ‚îÄ‚Üí add (11) ‚îÄ‚îÄ‚îê\n",
        "#     c (10) ‚îÄ‚îê                           ‚îÇ                        ‚îÇ\n",
        "#             ‚îú‚îÄ‚îÄ‚Üí [√∑] ‚îÄ‚îÄ‚Üí divide (5) ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ\n",
        "#     d (2) ‚îÄ‚îÄ‚îò                                                    ‚îú‚îÄ‚îÄ‚Üí [-] ‚îÄ‚îÄ‚Üí result (10)\n",
        "#                                                                  ‚îÇ\n",
        "#     e (1) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: multiply = a √ó b = 2 √ó 3 = 6\n",
        "# Step 2: divide = c √∑ d = 10 √∑ 2 = 5\n",
        "# Step 3: add = multiply + divide = 6 + 5 = 11\n",
        "# Step 4: result = add - e = 11 - 1 = 10\n",
        "\n",
        "# Final Answer: 10 ‚úÖ\n"
      ],
      "metadata": {
        "id": "wN7ePt2G6iFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######MORE COMPLEX EXAMPLE#####\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(5.0)\n",
        "y = tf.constant(3.0)\n",
        "\n",
        "# Build the graph step by step\n",
        "x_squared = x * x           # 25\n",
        "y_squared = y * y           # 9\n",
        "numerator = x_squared + y_squared  # 34\n",
        "denominator = x - y         # 2\n",
        "result = numerator / denominator   # 17\n",
        "\n",
        "print(\"Result:\", result.numpy())  # 17.0"
      ],
      "metadata": {
        "id": "OqxxZRVl8FZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Optimization\n",
        "TensorFlow can rearrange operations for speed:\n",
        "python# You write:\n",
        "result = (a * b) + (a * c)\n",
        "\n",
        "# TensorFlow optimizes to:\n",
        "result = a * (b + c)  # Fewer operations!\n",
        "\n",
        "2. Automatic Gradients (Backpropagation)\n",
        "\n",
        "python# TensorFlow tracks how to calculate derivatives\n",
        "\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "\n",
        "    y = x * x  # y = x¬≤\n",
        "\n",
        "    \n",
        "gradient = tape.gradient(y, x)  # dy/dx = 2x = 6\n",
        "\n",
        "print(\"Gradient:\", gradient.numpy())  # 6.0\n",
        "\n",
        "\n",
        "\n",
        "# The graph knows: \"y depends on x, so I can calculate dy/dx\"\n",
        "\n",
        "3. GPU Acceleration\n",
        "\n",
        "\n",
        "TensorFlow can run the whole graph on GPU automatically\n",
        "\n",
        "# No need to move data back and forth!\n",
        "\n"
      ],
      "metadata": {
        "id": "kYhBUcAc9gfo"
      }
    }
  ]
}